# -*- coding: utf-8 -*-
"""heartattack_random forest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XChNPULsopdgPxvQpNwZ4IJfF5tT4J5S
"""

import pandas as pd



# Load dataset
df = pd.read_csv("heart_attack_youngsters_india.csv")

# Display first few rows
df.head()

from sklearn.preprocessing import LabelEncoder

# Encode categorical columns
categorical_columns = ['Gender', 'Region', 'Urban/Rural', 'SES', 'Smoking Status', 'Alcohol Consumption',
                       'Diet Type', 'Physical Activity Level', 'Family History of Heart Disease',
                       'Diabetes', 'Hypertension', 'ECG Results', 'Chest Pain Type',
                       'Exercise Induced Angina', 'Heart Attack Likelihood']

for col in categorical_columns:
    df[col] = LabelEncoder().fit_transform(df[col])

df.head()

print(df.dtypes)  # Check data types of all columns
print(df.select_dtypes(include=['object']).head())  # Show first few rows of non-numeric columns

stress_mapping = {'Low': 0, 'Medium': 1, 'High': 2}
df['Stress Level'] = df['Stress Level'].map(stress_mapping)



import matplotlib.pyplot as plt# Plotting the distribution of numerical features
numerical_columns = ['Age', 'Cholesterol Levels (mg/dL)', 'BMI (kg/m²)', 'Screen Time (hrs/day)', 'Sleep Duration (hrs/day)']
df[numerical_columns].hist(bins=20, figsize=(12, 10), edgecolor='black')
plt.suptitle('Distributions of Numerical Features')
plt.show()

# Plotting countplot for categorical variables
import seaborn as sns
categorical_columns = ['Gender', 'Region', 'Urban/Rural', 'Smoking Status', 'Alcohol Consumption', 'Diet Type']
plt.figure(figsize=(12, 8))
for i, col in enumerate(categorical_columns, 1):
    plt.subplot(2, 3, i)
    sns.countplot(x=df[col], palette='Set2')
    plt.title(f'Countplot of {col}')
plt.tight_layout()
plt.show()

# Boxplot to detect outliers in numerical features
plt.figure(figsize=(12, 8))
for i, col in enumerate(numerical_columns, 1):
    plt.subplot(2, 3, i)
    sns.boxplot(x=df[col], palette='Set3')
    plt.title(f'Boxplot of {col}')
plt.tight_layout()
plt.show()



from sklearn.model_selection import train_test_split

# Define features (X) and target variable (y)
X = df.drop(columns=['Heart Attack Likelihood'])  # Features
y = df['Heart Attack Likelihood']  # Target variable

# Split the data into training and test sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Training set size:", X_train.shape)
print("Testing set size:", X_test.shape)

from sklearn.preprocessing import LabelEncoder

# Encode categorical columns
categorical_columns = ['Gender', 'Region', 'Urban/Rural', 'SES', 'Smoking Status', 'Alcohol Consumption',
                       'Diet Type', 'Physical Activity Level', 'Family History of Heart Disease',
                       'Diabetes', 'Hypertension', 'ECG Results', 'Chest Pain Type',
                       'Exercise Induced Angina', 'Stress Level', 'Heart Attack Likelihood']

label_encoder = LabelEncoder()
for col in categorical_columns:
    df[col] = label_encoder.fit_transform(df[col])

print(df.head())  # Check if all categorical values are converted

print(df.isnull().sum())  # Check missing values

# Ensure there are no extra spaces
df['Blood Pressure (systolic/diastolic mmHg)'] = df['Blood Pressure (systolic/diastolic mmHg)'].str.strip()

# Split into two separate columns
df[['Systolic BP', 'Diastolic BP']] = df['Blood Pressure (systolic/diastolic mmHg)'].str.split('/', expand=True)

# Convert to float
df['Systolic BP'] = df['Systolic BP'].astype(float)
df['Diastolic BP'] = df['Diastolic BP'].astype(float)

# Drop the original column
df.drop(columns=['Blood Pressure (systolic/diastolic mmHg)'], inplace=True)

from sklearn.ensemble import RandomForestClassifier
import joblib
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Define features and target again
X = df.drop(columns=['Heart Attack Likelihood'])
y = df['Heart Attack Likelihood']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Accuracy
print("Model Accuracy:", accuracy_score(y_test, y_pred))

# Save the trained model to a file
joblib.dump(model, 'heart_attack_model.pkl')  # Save the model

# Load the saved model
model = joblib.load('heart_attack_model.pkl')

# To make predictions on new data, use the loaded model
# For example, let's assume you have new user input data
# user_input = [your_input_data_here]  # Replace with actual data

# Make predictions
# prediction = model.predict(user_input)

# Predict heart attack likelihood for test data
y_pred = model.predict(X_test)

# Convert predictions into a DataFrame to compare with actual values
output_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})

# Show first 10 rows
print(output_df.head(10))

# Create a new column in the original dataset with model predictions
df['Predicted_Heart_Attack'] = model.predict(X)

# Show first 10 rows
print(df[['Heart Attack Likelihood', 'Predicted_Heart_Attack']].head(10))

import seaborn as sns
import matplotlib.pyplot as plt

# Plot actual vs. predicted
sns.countplot(x=df['Predicted_Heart_Attack'])
plt.title('Predicted Heart Attack Likelihood')
plt.xlabel('Likelihood (0 = No, 1 = Yes)')
plt.ylabel('Count')
plt.show()

import joblib

# Train model
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)  # Ensure X_train and y_train are preprocessed correctly

# Save the trained model
joblib.dump(model, "heart_attack_model.pkl")

print("✅ Model saved as 'heart_attack_model.pkl'")

import numpy as np
import pandas as pd
import joblib  # To save and load the model

# Load your trained model (assuming you saved it)
model = joblib.load('heart_attack_model.pkl')

# Load the LabelEncoders for encoding categorical variables
label_encoders = joblib.load('heart_attack_model.pkl')  # Load saved label encoders

# Define the feature names based on your model's training process
feature_names = ['Age', 'Gender', 'Region', 'Urban/Rural', 'SES', 'Smoking Status',
                 'Alcohol Consumption', 'Diet Type', 'Physical Activity Level',
                 'Screen Time (hrs/day)', 'Sleep Duration (hrs/day)',
                 'Family History of Heart Disease', 'Diabetes', 'Hypertension',
                 'Cholesterol Levels (mg/dL)', 'BMI (kg/m²)', 'Stress Level',
                 'Blood Pressure (systolic/diastolic mmHg)', 'Resting Heart Rate (bpm)',
                 'ECG Results', 'Chest Pain Type', 'Maximum Heart Rate Achieved',
                 'Exercise Induced Angina', 'Blood Oxygen Levels (SpO2%)',
                 'Triglyceride Levels (mg/dL)']

# Function to encode categorical features
def encode_user_input(user_input):
    # Encoding categorical variables using the label encoders
    encoded_input = []
    for i, feature in enumerate(feature_names):
        if feature in ['Region', 'Stress Level', 'Smoking Status', 'Alcohol Consumption', 'Diet Type', 'Physical Activity Level',
                       'Family History of Heart Disease', 'Diabetes', 'Hypertension', 'ECG Results', 'Chest Pain Type', 'Exercise Induced Angina']:
            # Encode using the appropriate label encoder
            encoded_value = label_encoders[feature].transform([user_input[i]]).item()
            encoded_input.append(encoded_value)
        else:
            # Keep numerical features as they are
            encoded_input.append(user_input[i])
    return np.array(encoded_input).reshape(1, -1)

# User input for testing (all inputs should be in the expected order)
print("Please enter your information:")

user_input = [
    int(input("Enter Age: ")),
    input("Enter Gender (Male/Female): "),  # User can type 'Male' or 'Female'
    input("Enter Region (e.g., 'Urban' or 'Rural'): "),  # User can type 'Urban' or 'Rural'
    input("Urban (yes or no): ").lower() == 'yes',  # Convert user input to boolean
    input("Enter Socioeconomic Status (Low/Medium/High): "),
    input("Smoking Status (Never/Occasionally/Regularly): "),  # User can type 'Never', 'Occasionally', or 'Regularly'
    input("Alcohol Consumption (Never/Occasionally/Regularly): "),  # User can type 'Never', 'Occasionally', or 'Regularly'
    input("Diet Type (Vegetarian/Non-Vegetarian/Vegan): "),  # User can type 'Vegetarian', 'Non-Vegetarian', 'Vegan'
    input("Physical Activity Level (Low/Medium/High): "),  # User can type 'Low', 'Medium', 'High'
    int(input("Enter Screen Time (hours/day): ")),
    int(input("Enter Sleep Duration (hours/day): ")),
    input("Family History of Heart Disease (Yes/No): "),  # User can type 'Yes' or 'No'
    input("Diabetes (Yes/No): "),  # User can type 'Yes' or 'No'
    input("Hypertension (Yes/No): "),  # User can type 'Yes' or 'No'
    float(input("Enter Cholesterol Levels (mg/dL): ")),
    float(input("Enter BMI (kg/m²): ")),
    input("Enter Stress Level (Low/Medium/High): "),  # User can type 'Low', 'Medium', 'High'
    int(input("Enter Systolic Blood Pressure: ")),
    int(input("Enter Diastolic Blood Pressure: ")),
    int(input("Enter Resting Heart Rate (bpm): ")),
    input("ECG Results (Normal/Abnormal): "),  # User can type 'Normal' or 'Abnormal'
    input("Chest Pain Type (Non-anginal/Typical/Asymptomatic): "),  # User can type 'Non-anginal', 'Typical', 'Asymptomatic'
    int(input("Maximum Heart Rate Achieved: ")),
    input("Exercise Induced Angina (Yes/No): "),  # User can type 'Yes' or 'No'
    float(input("Enter Blood Oxygen Levels (SpO2%): ")),
    int(input("Enter Triglyceride Levels (mg/dL): "))
]

# Automatically encode categorical features entered by the user
user_input_encoded = []

# Encode categorical values using label encoders for features that require encoding
for i, value in enumerate(user_input):
    if feature_names[i] in label_encoders:  # Check if this feature needs encoding
        encoded_value = label_encoders[feature_names[i]].transform([value]).item()
        user_input_encoded.append(encoded_value)
    else:
        # Keep numerical features as they are
        user_input_encoded.append(value)

# Convert encoded input into a numpy array and reshape for prediction
encoded_input_array = np.array(user_input_encoded).reshape(1, -1)

# Predict the likelihood of a heart attack
prediction = model.predict(encoded_input_array)

# Display result
if prediction[0] == 1:
    print("\n❌ High risk of Heart Attack!")
else:
    print("\n✅ Low risk of Heart Attack.")

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score

# Select features (X) and target (y)
X = df.drop(columns=['Heart Attack Likelihood'])  # Drop the target variable
y = df['Heart Attack Likelihood']

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Initialize the KNN classifier
knn = KNeighborsClassifier(n_neighbors=5)

# Train the model
knn.fit(X_train, y_train)

# Predict the target variable for the test set
y_pred = knn.predict(X_test)

# Evaluate the model
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print("Classification Report:")
print(classification_report(y_test, y_pred))

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

# Initialize the Logistic Regression model
log_reg = LogisticRegression(random_state=42)

# Train the model
log_reg.fit(X_train, y_train)

# Predict the target variable for the test set
y_pred = log_reg.predict(X_test)

# Evaluate the model
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print("Classification Report:")
print(classification_report(y_test, y_pred))

"""comparison of KNN and Logistic regression"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

# KNN Model (assuming KNN is already trained and you have the predictions from earlier)
from sklearn.neighbors import KNeighborsClassifier

# Initialize the KNN model
knn = KNeighborsClassifier(n_neighbors=5)

# Train the KNN model
knn.fit(X_train, y_train)

# Predict on the test set
y_pred_knn = knn.predict(X_test)

# Evaluation metrics for KNN
accuracy_knn = accuracy_score(y_test, y_pred_knn)
print("KNN Classification Report:")
print(classification_report(y_test, y_pred_knn))

# Logistic Regression Model (assuming you have already trained it)
log_reg = LogisticRegression(random_state=42)

# Train the model
log_reg.fit(X_train, y_train)

# Predict on the test set
y_pred_log_reg = log_reg.predict(X_test)

# Evaluation metrics for Logistic Regression
accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)
print("Logistic Regression Classification Report:")
print(classification_report(y_test, y_pred_log_reg))

print(f"KNN Model Accuracy: {accuracy_knn}")
print(f"Logistic Regression Accuracy: {accuracy_log_reg}")

# Confusion Matrix for KNN
cm_knn = confusion_matrix(y_test, y_pred_knn)

# Confusion Matrix for Logistic Regression
cm_log_reg = confusion_matrix(y_test, y_pred_log_reg)

# Plot Confusion Matrix for KNN
plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
sns.heatmap(cm_knn, annot=True, fmt="d", cmap="Blues", xticklabels=["No Heart Attack", "Heart Attack"], yticklabels=["No Heart Attack", "Heart Attack"])
plt.title("KNN Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")

# Plot Confusion Matrix for Logistic Regression
plt.subplot(1, 2, 2)
sns.heatmap(cm_log_reg, annot=True, fmt="d", cmap="Blues", xticklabels=["No Heart Attack", "Heart Attack"], yticklabels=["No Heart Attack", "Heart Attack"])
plt.title("Logistic Regression Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")

plt.tight_layout()
plt.show()

# Check the distribution of heart attack likelihood
heart_attack_distribution = df['Heart Attack Likelihood'].value_counts()

print(heart_attack_distribution)

import seaborn as sns
import matplotlib.pyplot as plt

# Visualize the distribution of heart attack likelihood
plt.figure(figsize=(6, 4))
sns.countplot(data=df, x='Heart Attack Likelihood', palette='Set2')
plt.title("Distribution of Heart Attack Likelihood")
plt.show()

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

"""Examine the Features of People with Heart Attack ('Yes')"""

# Filter data where heart attack likelihood is 'Yes'
heart_attack_yes = df[df['Heart Attack Likelihood'] == 'Yes']

# Show the first few rows of people with heart attack likelihood 'Yes'
print(heart_attack_yes.head())

# You can also summarize or analyze specific features
print(heart_attack_yes.describe())  # Summary statistics for those with heart attack likelihood 'Yes'



""" Visualizing the Characteristics of People with Heart Attack:"""



